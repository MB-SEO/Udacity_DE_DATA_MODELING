### About the project:
Main goal of this project is to practice data modeling fundamental and to build ETL pipeline

### Given Scenario:
Startup 'Sparkify' aims to analyze songs and user activity on the new music streamnig app.
Analytic team is eager to get hands on what songs users are interested to. 
Currently, only json file format is available.

### Given Task:
Perform data modeling with Postgres
Perform building an ETL process on given JSON file (song metadata and user log data)

### Given Datasets:
##### Song Dataset
- Songs dataset is a subset of Million Song Dataset. Each file in the dataset is in JSON format and contains meta-data about a song and the artist of that song.

##### Log Dataset
- Logs dataset is generated by Event Simulator. These log files in JSON format simulate activity logs from a music streaming application based on specified configurations.


### Data Model (Star schema)
![alt text](data/Star_schema_data_modeling_postgres.png)


### Running the Scripts:
1. Locate the terminal to PostgreSQL folder
2. In Terminal, - 'python create_tables.py' - Run Create database and tables.
3. In Terminal, - 'python etl.py' - Run ETL process and load data into database
4. check integrity of data by running test.ipynb 



